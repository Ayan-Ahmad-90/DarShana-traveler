Mood Analyzer Page – Judge Brief (text-only)
================================================

What it does
------------
- Blends quick intent questions + AI mood analysis from a face photo to rank travel destinations.
- Two flows: AI (default) and Manual; optional AR view opens a separate guide page.
- Outputs 3 destination recommendations, allows payment (Razorpay/Offline), and generates a PDF “trip ticket.”

Core flow (AI mode)
-------------------
1) Intent pre-questions (gating): vibe, climate, pace. Required before camera/analysis to tailor ranking.
2) Capture/Upload: open camera via face detection component or upload a photo (<=5MB). Countdown auto-capture after 5s of detected face.
3) Local face analysis: validates a face is present; shows face count; error if none.
4) Backend mood analysis: calls mood analyzer API (`getMoodAnalyzerUrl`, expected on port 3001). Receives mood, confidence, emotions, scores (energy/social/adventure), and recommended tags.
5) Recommendation ranking: filters destination list by mood scores and sorts by match + user intent. Shows top 3 cards; detail view with FAQ and highlights.
6) Payment: Razorpay by default; offline fallback if `VITE_PAYMENT_PROVIDER=offline` or SDK missing. Amount derived from destination pricePerDay * 3. Handles cancel error.
7) Ticket: After payment, shows confirmation card and allows PDF download (jsPDF) with destination, mood, amount, and date.

Manual flow (no camera)
-----------------------
- Steps: pick emoji mood, set sliders for energy/social/adventure, view top matches, proceed to payment, download ticket.
- Uses same destination dataset and payment/ticket logic (non-AI pricing formula differs: base 5000 + sliders).

Key UI/UX elements
------------------
- Mode switcher: AI / AR / Manual.
- AI stepper: intro → intent Qs → camera/upload → results → payment → ticket.
- Manual stepper: emoji mood → energy → social → adventure → matches → payment → ticket.
- Error states: file too large, no face detected, backend unreachable (explicit message to start backend: `cd backend && npm run dev`).
- Safe defaults: camera stops on unmount; streams cleaned up.

Configuration & deps
--------------------
- Env: `VITE_RAZORPAY_KEY_ID` (or offline provider), `VITE_PAYMENT_PROVIDER` (razorpay/offline).
- Backend: mood analyzer service reachable at `getMoodAnalyzerUrl` (defaults to port 3001 in messaging).
- Libraries: React + TypeScript, framer-motion, jsPDF, lucide-react icons, custom `useFaceDetection`, Razorpay SDK (script must be available globally), Tailwind utility classes present in code.

How to demo quickly
-------------------
1) Ensure backend mood analyzer running (`cd backend && npm run dev`) or mock it to return a MoodAnalyzeResponse.
2) Frontend: `npm install` then `npm run dev`; open the app.
3) Stay on AI mode. Answer the 3 intent questions (required).
4) Click Open Camera (or Upload Photo). Present face; wait for 5s auto-capture or click shutter.
5) Click “Analyze Mood & Recommend.” See recommendations; pick one if desired.
6) Click Pay (Razorpay pop-up or offline simulation). On success, download the ticket PDF.
7) Try Manual mode to confirm non-AI flow works without camera/backend.

Notes for judges
----------------
- No festivals/culture/heritage preview cards remain on the AI intro (per request); only intent Qs gate the flow.
- Offline payment sim just waits ~0.9s and resolves; good for demos without Razorpay.
- Face detection loads models lazily and throttles video checks to reduce load.
- Graceful fallbacks: if mood API unreachable, user sees a clear instruction to start backend.
